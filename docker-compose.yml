services:
  qwen3-vllm:
    image: vllm/vllm-openai:latest
    container_name: qwen3-vllm
    restart: unless-stopped
    ports:
      - "8080:8000"                       # наружу 8080 → внутри 8000
    environment:
      NVIDIA_VISIBLE_DEVICES: "all"
      VLLM_LOG_LEVEL: "INFO"
      VLLM_ATTENTION_BACKEND: "FLASHINFER"
      PYTORCH_CUDA_ALLOC_CONF: "expandable_segments:True"   # обязательно в кавычках
      # HF_TOKEN: "${HF_TOKEN:-}"         # раскомментируй при необходимости
    volumes:
      - /home/kovynev-sergey/.cache/huggingface:/root/.cache/huggingface
    gpus: all
    command:
      - "--model"
      - "unsloth/Qwen3-8B-unsloth-bnb-4bit"
      - "--quantization"
      - "bitsandbytes"
      - "--load-format"
      - "bitsandbytes"
      - "--dtype"
      - "auto"
      - "--max-model-len"
      - "4096"
      - "--kv-cache-dtype"
      - "fp8"
      - "--gpu-memory-utilization"
      - "0.75"
      - "--max-num-seqs"
      - "4"
      - "--max-num-batched-tokens"
      - "4096"
      - "--enforce-eager"
      - "--reasoning-parser"
      - "qwen3"
      - "--trust-remote-code"
      - "--host"
      - "0.0.0.0"
      - "--port"
      - "8000"
      - "--api-key"
      - "${API_KEY:-test}"
  weaviate:
    command:
    - --host
    - 0.0.0.0
    - --port
    - '8080'
    - --scheme
    - http
    image: cr.weaviate.io/semitechnologies/weaviate:1.32.8
    ports:
    - 8080:8080
    - 50051:50051
    volumes:
    - weaviate_data:/var/lib/weaviate
    restart: on-failure:0
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'none'          # BYO vectors: векторизатор не используется
      ENABLE_MODULES: ''                         # модули не включаем (не требуется)
      ENABLE_API_BASED_MODULES: 'false'
      CLUSTER_HOSTNAME: 'node1'
volumes:
  weaviate_data:
